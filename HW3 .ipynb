{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"notebookId":"d3b9a8ec-384b-4549-ab9a-dfa21c28f386"},"cells":[{"cell_type":"markdown","source":"# Урок3. Связь бизнес-показателей и DS-метрик","metadata":{"cellId":"9d0u449nrpfpvti3l3e9e"}},{"cell_type":"markdown","source":"**Домашнее задание**","metadata":{"cellId":"pb9d9y3hp9hr7q0nda6y"}},{"cell_type":"markdown","source":"1. обучить несколько разных моделей на наборе данных ССЗ (`train_case2.csv`): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n2. при обучении моделей обязательно использовать кроссвалидацию\n3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n4. сделать выводы о том, какая модель справилась с задачей лучше других\n5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n\np.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n\nИмеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \nДопустим, у нас две модели:\n\n- первая помечает 100 объектов как класс 1, но TP = 90\n- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n\nКакая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?","metadata":{"cellId":"grybf1gz9666m7nblcj2vh"}},{"cell_type":"markdown","source":"## Выполнение","metadata":{"cellId":"3rckp2cfrcsxjrvt5693v"}},{"cell_type":"markdown","source":"#### Импорт библиотек","metadata":{"cellId":"sm9rtrjkadllgdkpgq0r9"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix","metadata":{"cellId":"t89tuzf11d3pt5uq3st36","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"#### Загрузка датасета","metadata":{"cellId":"3494u544ep1jtmaf1mo2xs"}},{"cell_type":"markdown","source":"Таргет - наличие сердечно-сосудистых заболеваний (ССЗ)","metadata":{"cellId":"id3nrq0jjsqop0m5jm4rl"}},{"cell_type":"code","source":"df = pd.read_csv('train_case2.csv', ';')","metadata":{"cellId":"0uod33cdl5m695u8swxihc","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"#### Разделим наши данные на тренировочную и тестовую выборки","metadata":{"cellId":"mu9d0z9atf8zpsdri3qgch"}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', axis=1), \n                                                    df['cardio'], random_state=0)","metadata":{"cellId":"mx66wyua8t8c4dz3zff37","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"#### Преобразование","metadata":{"cellId":"u0ai5ijmrffdfmgv68cibw"}},{"cell_type":"markdown","source":"К полям:\n- `gender`, `cholesterol` применим OHE-кодирование\n- `age`, `height`, `weight`, `ap_hi`, `ap_lo` - standardScaler\n- `gluc`, `smoke`, `alco`, `active` - оставим пока как есть","metadata":{"cellId":"2rugo1i1fzmskkr7drpkm"}},{"cell_type":"code","source":"class ColumnSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to select a single column from the data frame to perform additional transformations on\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[self.key]\n\n\nclass NumberSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to select a single column from the data frame to perform additional transformations on\n    Use on numeric columns in the data\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]\n\n\nclass OHEEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n        self.columns = []\n\n    def fit(self, X, y=None):\n        self.columns = [\n            col for col in pd.get_dummies(X, prefix=self.key).columns\n        ]\n        return self\n\n    def transform(self, X):\n        X = pd.get_dummies(X, prefix=self.key)\n        test_columns = [col for col in X.columns]\n        for col_ in test_columns:\n            if col_ not in self.columns:\n                X[col_] = 0\n        return X[self.columns]\n\n\ncontinuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\ncat_cols = ['gender', 'cholesterol']\nbase_cols = ['gluc', 'smoke', 'alco', 'active']\n\ncontinuos_transformers = []\ncat_transformers = []\nbase_transformers = []\n\nfor cont_col in continuos_cols:\n    transfomer = Pipeline([('selector', NumberSelector(key=cont_col)),\n                           ('standard', StandardScaler())])\n    continuos_transformers.append((cont_col, transfomer))\n\nfor cat_col in cat_cols:\n    cat_transformer = Pipeline([('selector', ColumnSelector(key=cat_col)),\n                                ('ohe', OHEEncoder(key=cat_col))])\n    cat_transformers.append((cat_col, cat_transformer))\n\nfor base_col in base_cols:\n    base_transformer = Pipeline([('selector', NumberSelector(key=base_col))])\n    base_transformers.append((base_col, base_transformer))","metadata":{"cellId":"axouduj66fo2uy6zz5s2pa","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Теперь объединим все наши трансформеры с помощью FeatureUnion","metadata":{"cellId":"o6hae7zovcd5zr4oty279d"}},{"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion\n\nfeats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\nfeature_processing = Pipeline([('feats', feats)])\n\nfeature_processing.fit_transform(X_train)","metadata":{"cellId":"6sr43n0je5ol5pjq0fl1ac","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n         0.        ,  1.        ],\n       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n         0.        ,  1.        ],\n       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n         0.        ,  1.        ],\n       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n         0.        ,  1.        ]])"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"Добавим классификатор и запустим кросс-валидацию","metadata":{"cellId":"ckno9ffzbhsw3z7k5gcpa8"}},{"cell_type":"markdown","source":"#### Обучить несколько разных моделей на наборе данных ССЗ (`train_case2.csv`): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта","metadata":{"cellId":"43s6qrqq2epyumlc3rrjn"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"cellId":"2gtb0sf9xkks90k6i1jli","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"log_reg = Pipeline([('features', feats),\n                    ('classifier', LogisticRegression(random_state=42))])","metadata":{"cellId":"0h9jf38zxbjgmymc5vpsnsc","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def scores(classifier):\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import roc_auc_score\n\n    #запустим кросс-валидацию\n    cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n    cv_score = np.mean(cv_scores)\n    cv_score_std = np.std(cv_scores)\n\n    #обучим пайплайн на всем тренировочном датасете\n    classifier.fit(X_train, y_train)\n    y_score = classifier.predict_proba(X_test)[:, 1]\n    \n    # расчтаем метрики\n    b = 1\n    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n    fscore = (1 + b**2) * (precision * recall) / (b**2 * precision + recall)\n    roc_auc_score = roc_auc_score(y_test, y_score)\n    ix = np.argmax(fscore)\n    \n \n    return [round(i, 3) for i in [cv_score, thresholds[ix], fscore[ix], precision[ix], recall[ix], roc_auc_score]]","metadata":{"cellId":"2lxhhhfveg2xw7mqp026e","trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"cellId":"wa7quikmtk6df3sld83c","trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#!M\nresults = pd.DataFrame([\n    scores(classifier=Pipeline([('features', feats), ('classifier', LogisticRegression(random_state=42))])),\n    scores(classifier=Pipeline([('features', feats), ('classifier', RandomForestClassifier(random_state=42))])),\n    scores(classifier=Pipeline([('features', feats), ('classifier', DecisionTreeClassifier(max_depth=4, random_state=42))])),\n], columns=['CV_score', 'Best Threshold', 'F-Score', 'Precision', 'Recall', 'ROC AUC score'])\n\nresults['models'] = ['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier']\nresults = results.set_index('models')","metadata":{"cellId":"7v0np0yt7t8b6rbe24urka","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"results","metadata":{"cellId":"t19m8lnhnhmmd70eepilus","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"                        CV_score  Best Threshold  F-Score  Precision  Recall  \\\nmodels                                                                         \nLogisticRegression         0.787           0.387    0.730      0.647   0.838   \nRandomForestClassifier     0.773           0.350    0.719      0.643   0.816   \nDecisionTreeClassifier     0.787           0.380    0.731      0.647   0.840   \n\n                        ROC AUC score  \nmodels                                 \nLogisticRegression              0.784  \nRandomForestClassifier          0.771  \nDecisionTreeClassifier          0.789  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CV_score</th>\n      <th>Best Threshold</th>\n      <th>F-Score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>ROC AUC score</th>\n    </tr>\n    <tr>\n      <th>models</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.787</td>\n      <td>0.387</td>\n      <td>0.730</td>\n      <td>0.647</td>\n      <td>0.838</td>\n      <td>0.784</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.773</td>\n      <td>0.350</td>\n      <td>0.719</td>\n      <td>0.643</td>\n      <td>0.816</td>\n      <td>0.771</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.787</td>\n      <td>0.380</td>\n      <td>0.731</td>\n      <td>0.647</td>\n      <td>0.840</td>\n      <td>0.789</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"**Вывод**\n\nСудя по ROC_AUC, дерево решений является наилучшей моделью, но:\n- В данной задаче целесообразнее максимизировать Recall для того, чтобы минимизировать случаи, когда болезнь была не распознана.\n- Значения метрик различаются не очень существенно. Можно ещё попробовать перебрать параметры. Возможно, наилучший результат покажет другая модель.","metadata":{"cellId":"m7uhio6azlpqyyr19ux3wg"}},{"cell_type":"code","source":"","metadata":{"cellId":"7bhfykfiwjdajtv5p6dadu"},"outputs":[],"execution_count":null}]}